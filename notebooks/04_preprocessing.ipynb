{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Data Preprocessing\n",
    "\n",
    "In this notebook, we perform data preprocessing for different machine learning models.\n",
    "The steps include:\n",
    "- Loading the feature-engineered datasets\n",
    "- Imputing missing values based on the training set\n",
    "- Applying model-specific preprocessing:\n",
    "  - Logistic Regression: scaling and one-hot encoding\n",
    "  - Random Forest: use imputed features directly\n",
    "  - XGBoost: same as Random Forest\n",
    "  - LightGBM: convert categorical columns to 'category' dtype\n",
    "- Saving the preprocessed datasets for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Import libraries\n",
    "import sys\n",
    "# Add project root directory to sys.path\n",
    "sys.path.append(str(Path('.').resolve().parent))  # or adjust as needed\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import scripts.preprocessing\n",
    "importlib.reload(scripts.preprocessing)\n",
    "\n",
    "from scripts.preprocessing import (\n",
    "    impute_missing_values,\n",
    "    preprocess_for_logistic,\n",
    "    select_low_vif_features,\n",
    "    preprocess_for_tree_models,\n",
    "    preprocess_for_lightgbm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Define file paths\n",
    "TRAIN_PATH = Path('../data/processed/train_fe.csv')\n",
    "VAL_PATH = Path('../data/processed/val_fe.csv')\n",
    "TEST_PATH = Path('../data/processed/test_fe.csv')\n",
    "\n",
    "OUTPUT_DIR = Path('../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load feature-engineered datasets\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_val = pd.read_csv(VAL_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Load feature-engineered datasets\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_val = pd.read_csv(VAL_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Separate features and target\n",
    "TARGET = 'DRK_YN'\n",
    "X_train = df_train.drop(columns=[TARGET])\n",
    "y_train = df_train[TARGET]\n",
    "X_val = df_val.drop(columns=[TARGET])\n",
    "y_val = df_val[TARGET]\n",
    "X_test = df_test.drop(columns=[TARGET])\n",
    "y_test = df_test[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Impute missing values\n",
    "X_train_imp, X_val_imp, X_test_imp = impute_missing_values(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Identify categorical columns\n",
    "categorical_cols = ['sex'] if 'sex' in X_train.columns else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Preprocessing per model\n",
    "# Logistic Regression\n",
    "X_train_lr, X_val_lr, X_test_lr = preprocess_for_logistic(X_train_imp, X_val_imp, X_test_imp, categorical_cols)\n",
    "\n",
    "# Random Forest\n",
    "X_train_rf, X_val_rf, X_test_rf = preprocess_for_tree_models(X_train_imp, X_val_imp, X_test_imp)\n",
    "\n",
    "# XGBoost\n",
    "X_train_xgb, X_val_xgb, X_test_xgb = preprocess_for_tree_models(X_train_imp, X_val_imp, X_test_imp)\n",
    "\n",
    "# LightGBM\n",
    "X_train_lgb, X_val_lgb, X_test_lgb = preprocess_for_lightgbm(X_train_imp, X_val_imp, X_test_imp, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All preprocessed datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "## 9. Save preprocessed datasets\n",
    "# Logistic Regression datasets\n",
    "X_train_lr.to_csv(OUTPUT_DIR / 'X_train_lr.csv', index=False)\n",
    "X_val_lr.to_csv(OUTPUT_DIR / 'X_val_lr.csv', index=False)\n",
    "X_test_lr.to_csv(OUTPUT_DIR / 'X_test_lr.csv', index=False)\n",
    "y_train.to_csv(OUTPUT_DIR / 'y_train_lr.csv', index=False)\n",
    "y_val.to_csv(OUTPUT_DIR / 'y_val_lr.csv', index=False)\n",
    "y_test.to_csv(OUTPUT_DIR / 'y_test_lr.csv', index=False)\n",
    "\n",
    "# Random Forest datasets\n",
    "X_train_rf.to_csv(OUTPUT_DIR / 'X_train_rf.csv', index=False)\n",
    "X_val_rf.to_csv(OUTPUT_DIR / 'X_val_rf.csv', index=False)\n",
    "X_test_rf.to_csv(OUTPUT_DIR / 'X_test_rf.csv', index=False)\n",
    "y_train.to_csv(OUTPUT_DIR / 'y_train_rf.csv', index=False)\n",
    "y_val.to_csv(OUTPUT_DIR / 'y_val_rf.csv', index=False)\n",
    "y_test.to_csv(OUTPUT_DIR / 'y_test_rf.csv', index=False)\n",
    "\n",
    "# XGBoost datasets\n",
    "X_train_xgb.to_csv(OUTPUT_DIR / 'X_train_xgb.csv', index=False)\n",
    "X_val_xgb.to_csv(OUTPUT_DIR / 'X_val_xgb.csv', index=False)\n",
    "X_test_xgb.to_csv(OUTPUT_DIR / 'X_test_xgb.csv', index=False)\n",
    "y_train.to_csv(OUTPUT_DIR / 'y_train_xgb.csv', index=False)\n",
    "y_val.to_csv(OUTPUT_DIR / 'y_val_xgb.csv', index=False)\n",
    "y_test.to_csv(OUTPUT_DIR / 'y_test_xgb.csv', index=False)\n",
    "\n",
    "# LightGBM datasets\n",
    "X_train_lgb.to_csv(OUTPUT_DIR / 'X_train_lgb.csv', index=False)\n",
    "X_val_lgb.to_csv(OUTPUT_DIR / 'X_val_lgb.csv', index=False)\n",
    "X_test_lgb.to_csv(OUTPUT_DIR / 'X_test_lgb.csv', index=False)\n",
    "y_train.to_csv(OUTPUT_DIR / 'y_train_lgb.csv', index=False)\n",
    "y_val.to_csv(OUTPUT_DIR / 'y_val_lgb.csv', index=False)\n",
    "y_test.to_csv(OUTPUT_DIR / 'y_test_lgb.csv', index=False)\n",
    "\n",
    "print(\"All preprocessed datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/pytorch/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "# Apply VIF-based feature selection\n",
    "X_train_lr_vif = select_low_vif_features(X_train_lr)\n",
    "# Make sure val/test have same columns\n",
    "X_val_lr_vif = X_val_lr[X_train_lr_vif.columns]\n",
    "X_test_lr_vif = X_test_lr[X_train_lr_vif.columns]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
